# Default values for catalog-server.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

# -- Number of catalog-server replicas to deploy
replicaCount: 1

image:
  # -- catalog-server image repository
  repository: radarbase/radar-schemas-tools
  # -- catalog-server image tag (immutable tags are recommended)
  # Overrides the image tag whose default is the chart appVersion.
  tag: 0.8.2
  # -- catalog-server image pull policy
  pullPolicy: IfNotPresent

# -- Docker registry secret names as an array
imagePullSecrets: []

# -- String to partially override catalog-server.fullname template with a string (will prepend the release name)
nameOverride: ""
# -- String to fully override catalog-server.fullname template with a string
fullnameOverride: ""

# -- Configure catalog-server pods' Security Context
podSecurityContext:
  fsGroup: 101

# -- Configure Appconfig containers' Security Context
securityContext: {}
  # capabilities:
  #   drop:
  #   - ALL
  # readOnlyRootFilesystem: true
  # runAsNonRoot: true
  # runAsUser: 1000

service:
  # -- Kubernetes Service type
  type: ClusterIP
  # -- catalog-server port
  port: 9010

resources:
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # -- CPU/Memory resource limits
  # limits:
  #   cpu: 200m
  #   memory: 512Mi
  # -- CPU/Memory resource requests
  requests:
    cpu: 100m
    memory: 256Mi

persistence:
  # -- Enable persistence using PVC
  enabled: true
  ## If defined, storageClassName: <storageClass>
  ## If set to "-", storageClassName: "", which disables dynamic provisioning
  ## If undefined (the default) or set to null, no storageClassName spec is
  ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
  ##   GKE, AWS & OpenStack)
  ##
  # storageClass: "-"
  ##
  ## If you want to reuse an existing claim, you can pass the name of the PVC using
  ## the existingClaim variable
  # existingClaim: your-claim
  # -- PVC Access Mode for catalog-server volume
  accessMode: ReadWriteOnce
  # -- PVC Storage Request for catalog-server volume
  size: 5Mi

# -- Node labels for pod assignment
nodeSelector: {}

# -- Toleration labels for pod assignment
tolerations: []

# -- Affinity labels for pod assignment
affinity: {}

# -- Extra environment variables
extraEnvVarsInit: []
#  - name: BEARER_AUTH
#    value: true

# -- Custom livenessProbe that overrides the default one
customLivenessProbe: {}

livenessProbe:
  # -- Enable livenessProbe
  enabled: true
  # -- Initial delay seconds for livenessProbe
  initialDelaySeconds: 5
  # -- Period seconds for livenessProbe
  periodSeconds: 60
  # -- Timeout seconds for livenessProbe
  timeoutSeconds: 5
  # -- Success threshold for livenessProbe
  successThreshold: 1
  # -- Failure threshold for livenessProbe
  failureThreshold: 3

# -- Custom readinessProbe that overrides the default one
customReadinessProbe: {}

readinessProbe:
  # -- Enable readinessProbe
  enabled: true
  # -- Initial delay seconds for readinessProbe
  initialDelaySeconds: 5
  # -- Period seconds for readinessProbe
  periodSeconds: 60
  # -- Timeout seconds for readinessProbe
  timeoutSeconds: 5
  # -- Success threshold for readinessProbe
  successThreshold: 1
  # -- Failure threshold for readinessProbe
  failureThreshold: 3

# -- Network policy defines who can access this application and who this applications has access to
# @default -- check `values.yaml`
networkpolicy:
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          kubernetes.io/metadata.name: '{{ .Release.Namespace }}'
      podSelector:
        matchLabels:
          app.kubernetes.io/name: management-portal
    - namespaceSelector:
        matchLabels:
          kubernetes.io/metadata.name: '{{ .Release.Namespace }}'
      podSelector:
        matchLabels:
          app.kubernetes.io/name: radar-s3-connector
  egress:
  - to:
    - ipBlock:
        cidr: 0.0.0.0/0
        except:
        - 10.0.0.0/8
        - 192.168.0.0/16
        - 172.16.0.0/12
  - to:
    - namespaceSelector:
        matchLabels:
          kubernetes.io/metadata.name: kube-system
      podSelector:
        matchLabels:
          k8s-app: kube-dns
    ports:
      - port: 53
        protocol: UDP
      - port: 53
        protocol: TCP
  - to:
    - namespaceSelector:
        matchLabels:
          kubernetes.io/metadata.name: '{{ .Release.Namespace }}'
      podSelector:
        matchLabels:
          app.kubernetes.io/name: cp-kafka
    - namespaceSelector:
        matchLabels:
          kubernetes.io/metadata.name: '{{ .Release.Namespace }}'
      podSelector:
        matchLabels:
          app.kubernetes.io/name: cp-schema-registry

# -- number of Kafka brokers to look for
kafka_num_brokers: 3
# -- URI of Kafka brokers
kafka: cp-kafka-headless:9092
# -- URL of the confluent schema registry
schema_registry: http://cp-schema-registry:8081

# -- Additional kafka properties such as security config. The template replaces `_` with `.` in keys so property keys can be specified using `_` instead of `.`. For example `security_protocol` is same as `security.protocol` kafka config.
kafkaProperties:
# -- Protocol used to communicate with brokers. Valid values are: PLAINTEXT, SSL, SASL_PLAINTEXT, SASL_SSL.
  security_protocol: PLAINTEXT

sources:
  # -- Only include given specification directory files. You can use File glob syntax as described in <https://docs.oracle.com/javase/8/docs/api/java/nio/file/FileSystem.html#getPathMatcher-java.lang.String-> If include is specified, exclude will be ignored. The glob pattern should start from the specifications directory.
  include: []
  # -- Exclude all given specification directory files. You can use File glob syntax as described in <https://docs.oracle.com/javase/8/docs/api/java/nio/file/FileSystem.html#getPathMatcher-java.lang.String-> If include is specified, exclude will be ignored. The glob pattern should start from the specifications directory.
  exclude: []
    # - active/*
    # - passive/*1.0.0*
  # -- active source specification, as done in RADAR-schemas/specifications/active. The array elements should be the full YAML specification.
  active: []
  # -- connector source specification, as done in RADAR-schemas/specifications/connector. The array elements should be the full YAML specification.
  connector: []
  # -- monitor source specification, as done in RADAR-schemas/specifications/monitor. The array elements should be the full YAML specification.
  monitor: []
  # -- passive source specification, as done in RADAR-schemas/specifications/passive. The array elements should be the full YAML specification.
  passive: []
  # -- push source specification, as done in RADAR-schemas/specifications/push. The array elements should be the full YAML specification.
  push: []
  # -- stream source specification, as done in RADAR-schemas/specifications/stream. The array elements should be the full YAML specification.
  stream: []

schemas:
  # -- Only include given schema directory files. You can use File glob syntax as described in <https://docs.oracle.com/javase/8/docs/api/java/nio/file/FileSystem.html#getPathMatcher-java.lang.String->. If include is specified, exclude will be ignored. The glob pattern should start from the commons directory.
  include: []
  # -- Exclude all given schema directory files. You can use File glob syntax as described in <https://docs.oracle.com/javase/8/docs/api/java/nio/file/FileSystem.html#getPathMatcher-java.lang.String->. If include is specified, exclude will be ignored. The glob pattern should start from the commons directory.
  exclude: []
    # - active/*
    # - passive/*1.0.0*
  # -- active record schemas, as done in RADAR-schemas/commons/active. The object fields should be the file name, e.g. `application/application_uptime.avsc`.
  active: {}
  # -- catalogue record schemas, as done in RADAR-schemas/commons/catalogue. The object fields should be the file name, e.g. `application/application_uptime.avsc`.
  catalogue: {}
  # -- connector record schemas, as done in RADAR-schemas/commons/connector. The object fields should be the file name, e.g. `application/application_uptime.avsc`.
  connector: {}
  # -- catalogue record schemas, as done in RADAR-schemas/commons/kafka. The object fields should be the file name, e.g. `application/application_uptime.avsc`.
  kafka: {}
  # -- monitor record schemas, as done in RADAR-schemas/commons/monitor. The object fields should be the file name, e.g. `application/application_uptime.avsc`.
  monitor: {}
  # -- passive record schemas, as done in RADAR-schemas/commons/passive. The object fields should be the file name, e.g. `application/application_uptime.avsc`.
  passive: {}
  # -- push record schemas, as done in RADAR-schemas/commons/push. The object fields should be the file name, e.g. `application/application_uptime.avsc`.
  push: {}
  # -- stream record schemas, as done in RADAR-schemas/commons/stream. The object fields should be the file name, e.g. `application/application_uptime.avsc`.
  stream: {}

cc:
  # -- set to true if using Confluent Cloud for kafka cluster and schema registry
  enabled: false
  # -- URL of the bootstrap server of Confluent Cloud based kafka cluster
  bootstrapServerurl: confluent-url
  # -- API key of the Confluent Cloud based kafka cluster
  apiKey: ccApikey
  # -- API secret of the Confluent Cloud based kafka cluster
  apiSecret: ccApiSecret
  # -- API key of the Confluent Cloud based schema registry
  schemaRegistryApiKey: srApiKey
  # -- API secret of the Confluent Cloud based schema registry
  schemaRegistryApiSecret: srApiSecret
