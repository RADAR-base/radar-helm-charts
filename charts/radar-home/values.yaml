# Default values for radar-home.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

# -- Number of Appconfig replicas to deploy
replicaCount: 1

image:
  # -- Image registry
  registry: ghcr.io
  # -- Image repository
  repository: radar-base/radar-home/radar-home
  # -- Image tag (immutable tags are recommended)
  # Overrides the image tag whose default is the chart appVersion.
  tag:
  # -- Image digest in the way sha256:aa.... Please note this parameter, if set, will override the tag
  digest: ""
  # -- Image pull policy
  pullPolicy: IfNotPresent
  # -- Optionally specify an array of imagePullSecrets.
  # Secrets must be manually created in the namespace.
  # e.g:
  # pullSecrets:
  #   - myRegistryKeySecretName
  #
  pullSecrets: []

# -- String to partially override radar-home.fullname template with a string (will prepend the release name)
nameOverride: ""
# -- String to fully override radar-home.fullname template with a string
fullnameOverride: ""

# -- Kubernetes namespace that Appconfig is going to be deployed on
namespace: default

service:
  # -- Kubernetes Service type
  type: ClusterIP
  # -- Port
  port: 8080

# -- Reconfigure Ingress to not force TLS
disable_tls: false

ingress:
  # -- Enable ingress controller resource
  enabled: true
  # -- Annotations that define default ingress class, certificate issuer
  # @default -- check values.yaml
  annotations:
    cert-manager.io/cluster-issuer: letsencrypt-prod
  # -- Path within the url structure
  path: /
  # -- Ingress Path type
  pathType: ImplementationSpecific
  # -- IngressClass that will be be used to implement the Ingress (Kubernetes 1.18+)
  ingressClassName: nginx
  # -- Hosts to accept requests from
  hosts:
    - localhost
  tls:
    # -- TLS Secret Name
    secretName: radar-base-tls

resources:
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.

  # -- CPU/Memory resource limits
  limits:
    cpu: 200m
  # -- CPU/Memory resource requests
  requests:
    cpu: 10m
    memory: 5Mi

# -- Node labels for pod assignment
nodeSelector: {}

# -- Toleration labels for pod assignment
tolerations: []

# -- Affinity labels for pod assignment
affinity: {}

# -- Extra environment variables
extraEnvVars: []
#  - name: BEARER_AUTH
#    value: true

# -- Custom livenessProbe that overrides the default one
customLivenessProbe: {}

livenessProbe:
  # -- Enable livenessProbe
  enabled: true
  # -- Initial delay seconds for livenessProbe
  initialDelaySeconds: 5
  # -- Period seconds for livenessProbe
  periodSeconds: 30
  # -- Timeout seconds for livenessProbe
  timeoutSeconds: 5
  # -- Success threshold for livenessProbe
  successThreshold: 1
  # -- Failure threshold for livenessProbe
  failureThreshold: 3

# -- Custom readinessProbe that overrides the default one
customReadinessProbe: {}

readinessProbe:
  # -- Enable readinessProbe
  enabled: true
  # -- Initial delay seconds for readinessProbe
  initialDelaySeconds: 5
  # -- Period seconds for readinessProbe
  periodSeconds: 30
  # -- Timeout seconds for readinessProbe
  timeoutSeconds: 5
  # -- Success threshold for readinessProbe
  successThreshold: 1
  # -- Failure threshold for readinessProbe
  failureThreshold: 3

# -- Custom startupProbe that overrides the default one
customStartupProbe: {}

startupProbe:
  # -- Enable startupProbe
  enabled: true
  # -- Initial delay seconds for startupProbe
  initialDelaySeconds: 5
  # -- Period seconds for startupProbe
  periodSeconds: 10
  # -- Timeout seconds for startupProbe
  timeoutSeconds: 10
  # -- Success threshold for startupProbe
  successThreshold: 1
  # -- Failure threshold for startupProbe
  failureThreshold: 30

# -- Network policy defines who can access this application and who this applications has access to
# @default -- check `values.yaml`
networkpolicy:
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          kubernetes.io/metadata.name: '{{ .Release.Namespace }}'
      podSelector:
        matchLabels:
          app.kubernetes.io/name: ingress-nginx
  egress:
  - to:
    - namespaceSelector:
        matchLabels:
          kubernetes.io/metadata.name: kube-system
      podSelector:
        matchLabels:
          k8s-app: kube-dns
    ports:
      - port: 53
        protocol: UDP
      - port: 53
        protocol: TCP

s3:
  # -- Enable link to S3
  enabled: false
  # -- URL to S3
  url:

dashboard:
  # -- Enable link to dashboard
  enabled: false
  # -- URL to dashboard
  url:

appConfig:
  # -- Enable link to app-config service
  enabled: false

uploadPortal:
  # -- Enable link to upload portal
  enabled: false

restAuthorizer:
  # -- Enable link to rest source authorizer
  enabled: false

monitoring:
  # -- Enable link to the monitoring stack, usually Prometheus
  enabled: false
  # -- URL to the monitoring stack, usually Prometheus
  url:

logging:
  # -- Enable link to the logging stack, usually Graylog
  enabled: false
  # -- URL to the monitoring stack, usually Graylog
  url:

# Pod Disruption Budget configuration
podDisruptionBudget:
  # -- Enable Pod Disruption Budget
  enabled: true
  # -- Minimum number of pods that must be available during disruptions
  minAvailable: 1
  # -- Maximum number of pods that can be unavailable during disruptions
  # maxUnavailable:
