apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ template "radar-output.fullname" . }}
  labels:
    app: {{ template "radar-output.name" . }}
    chart: {{ template "radar-output.chart" . }}
    release: {{ .Release.Name }}
    heritage: {{ .Release.Service }}
data:
  config.yaml: |
    service:
      # Whether to run the application as a polling service.
      enable: true
      # Polling interval in seconds.
      interval: {{ .Values.worker.interval | int }}

    {{- with .Values.source }}
    source:
      type: "{{ .type }}"
      # Minio S3 settings
      s3:
        endpoint: "{{ .s3.endpoint }}"
        bucket: "{{ .s3.bucket }}"
        {{- if .s3.connectTimeout }}
        connectTimeout: {{ .s3.connectTimeout | int }}
        {{- end }}
        {{- if .s3.writeTimeout }}
        writeTimeout: {{ .s3.writeTimeout | int }}
        {{- end }}
        {{- if .s3.readTimeout }}
        readTimeout: {{ .s3.readTimeout | int }}
        {{- end }}
      azure:
        endpoint: "{{ .azure.endpoint }}"
        container: "{{ .azure.container }}"
        {{- if .azure.connectTimeout }}
        connectTimeout: {{ .azure.connectTimeout | int }}
        {{- end }}
        {{- if .azure.responseTimeout }}
        responseTimeout: {{ .azure.responseTimeout | int }}
        {{- end }}
        {{- if .azure.writeTimeout }}
        writeTimeout: {{ .azure.writeTimeout | int }}
        {{- end }}
        {{- if .azure.readTimeout }}
        readTimeout: {{ .azure.readTimeout | int }}
        {{- end }}
    {{- end }}

    {{- with .Values.target }}
    target:
      type: "{{ .type }}"
      # Minio S3 settings
      s3:
        endpoint: "{{ .s3.endpoint }}"
        bucket: "{{ .s3.bucket }}"
        {{- if .s3.connectTimeout }}
        connectTimeout: {{ .s3.connectTimeout | int }}
        {{- end }}
        {{- if .s3.writeTimeout }}
        writeTimeout: {{ .s3.writeTimeout | int }}
        {{- end }}
        {{- if .s3.readTimeout }}
        readTimeout: {{ .s3.readTimeout | int }}
        {{- end }}
      azure:
        endpoint: "{{ .azure.endpoint }}"
        container: "{{ .azure.container }}"
        {{- if .azure.connectTimeout }}
        connectTimeout: {{ .azure.connectTimeout | int }}
        {{- end }}
        {{- if .azure.responseTimeout }}
        responseTimeout: {{ .azure.responseTimeout | int }}
        {{- end }}
        {{- if .azure.writeTimeout }}
        writeTimeout: {{ .azure.writeTimeout | int }}
        {{- end }}
        {{- if .azure.readTimeout }}
        readTimeout: {{ .azure.readTimeout | int }}
        {{- end }}
    {{- end }}

    redis:
      uri: "{{ .Values.redis.uri }}"
      lockPrefix: radar-output/lock

    # Compression characteristics
    compression:
      # Compression type: none, zip or gzip
      type: gzip
      # Compression Factory class
      # factory: org.radarbase.hdfs.data.CompressionFactory
      # Additional compression properties
      # properties: {}

    # File format
    format:
      # Format type: CSV or JSON
      type: csv
      # Whether to deduplicate the files in each topic by default
      deduplication:
        enable: true
      # Format factory class
      # factory: org.radarbase.hdfs.data.FormatFactory
      # Additional format properties
      # properties: {}

    # Worker settings
    worker:
      # Maximum number of files and converters to keep open while processing
      cacheSize: {{ .Values.worker.cacheSize | int }}
      # Maximum number of offsets in cache.
      cacheOffsetsSize: {{ .Values.worker.cacheOffsetsSize | int }}
      # Number of threads to do processing with
      numThreads: {{ .Values.worker.numThreads | int }}
      # Maximum number of files to process in any given topic.
      maxFilesPerTopic: {{ .Values.worker.maxFilesPerTopic | int }}
      minimumFileAge: {{ .Values.worker.minimumFileAge | int }}

    cleaner:
      # Enable cleaning up old source files
      enable: {{ gt (int (toString (.Values.cleaner.age))) 0 }}
      # Interval in seconds to clean data
      interval: 1800  # 21 minutes
      # Number of days after which a source file is considered old
      age: {{ .Values.cleaner.age }}

    # Path settings
    paths:
      # Input directories in HDFS
      inputs:
        - "{{ .Values.paths.input }}"
      # Root temporary directory for local file processing.
      temp: /output/+tmp
      # Output directory
      output: "{{ .Values.paths.output }}"
      # Output path construction factory
      factory: {{ .Values.paths.factory }}
      # Additional properties
      properties:
        {{ .Values.paths.properties | toYaml | indent 8 | trim }}

    # Individual topic configuration
    {{- if .Values.topics }}
    topics:
      {{ .Values.topics | toYaml | indent 6 | trim }}
    {{- else }}
    topics: {}
    {{- end }}
